# public/robots.txt

User-agent: *
Allow: /

# Content usage signals
Content-Signal: search=yes
Content-Signal: ai-input=yes
Content-Signal: ai-train=no

# Block AI model training crawlers
User-agent: GPTBot
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: ClaudeBot
Disallow: /

User-agent: Applebot-Extended
Disallow: /

User-agent: Amazonbot
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: meta-externalagent
Disallow: /

# Sitemap
Sitemap: https://doitwithai.tools/sitemap.xml
